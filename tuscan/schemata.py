#!/usr/bin/env python2
#
# Copyright 2016 Kareem Khazem. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.


from datetime import datetime
from voluptuous import All, Any, Length, Optional, Range, Required
from voluptuous import Schema
from yaml import load


# We can't merely specify that strings ought to be of type 'str' in the
# schemata, since Python 2.7 treats unicode strings specially.
_nonempty_string = All(Any(str, unicode), Length(min=1))
_string = All(Any(str, unicode))


"""Schema for the deps.yaml files located in each stage directory"""
stage_deps_schema = Schema({
    # The name of the stage (this does not exist in the deps.yaml file
    # itself, but is added to the data structure after the file is read)
    Required("name"): _nonempty_string,
    # Data needed to build the container
    Required("build"): Schema({
        # Stages that need to have run before we build this stage
        Optional("stages"): [_nonempty_string],
        # Files that we need to copy into the build context (i.e. files
        # that are mentioned in the Dockerfile, or are needed for some
        # other reason)
        Optional("copy_files"): [_nonempty_string],
    }),
    # Data needed to run the container
    Required("run"): Schema({
        Optional("dependencies"): Schema({
            #Stages that need to have run before we run this stage
            Optional("stages"): [_nonempty_string],
            # Data containers that are used during the run of this stage
            Optional("data_containers"): [_nonempty_string],
            # Directories that will be mounted in this stage's # container
            Optional("local_mounts"): [_nonempty_string],
        }),
        # Instead of doing 'docker run', run a custom command
        Optional("command_override"): _nonempty_string,
        # Redirect the running container's output to a file
        Optional("stdout"): _nonempty_string,
        Optional("stderr"): _nonempty_string,
        # Do a shell command after this stage's container exits
        Optional("post_exit"): _nonempty_string,
        # Indicates that this stage is the root of the dependency tree
        # (the final stage to be run), and may take over the console
        Optional("top_level"): bool,
        # Whether to pass the --rm flag to docker run
        Optional("rm_container"): bool,
    })
})


"""Schema for data_containers.yaml file"""
data_containers_schema = Schema([
    Schema({
        # The Docker name of this data container
        Required("name"): _nonempty_string,
        # Where the data container will be mounted
        Required("mountpoint"): _nonempty_string,
        # We pass the location of data containers to stages using a
        # command line argument. We relate locations to the command line
        # switch using this key, such that if we have a data container
        # specified like this:
        # {"mountpoint": "/toolchain", "switch": "toolchain-dir"}
        # then any stage that uses this data container will get the
        # command-line argument
        # --toolchain-dir /toolchain
        Required("switch"): _nonempty_string
    })
])


"""Schema for JSON files that are generated by the make_package stage"""
make_package_schema = Schema({
    Required("build_name"): _nonempty_string,
    # This will be true for bootstrap packages, and false otherwise.
    # The results of boostrap packages will not fully conform to this
    # schema (see tuscan/empty.json for what fields bootstrap packages
    # have); clients should not attempt to validate results of bootstrap
    # packages.
    Required("bootstrap"): bool,
    Required("return_code"): All(int, Range(min=0)),
    Required("time"): All(int, Range(min=0)),
    Required("toolchain"): _nonempty_string,
    Required("errors"): list,
    # What packages are provided by this build? This will be a list of
    # package names, possibly including meta-packages (like 'sh') that
    # don't really exist but are provided by bash.
    Required("build_provides"): list,
    # What packages are depended on by this build? This will be a list of
    # package names, possibly including meta-packages (like 'sh') that
    # don't really exist but are provided by bash.
    Required("build_depends"): list,
    Required("log"): [
        # Logs have a head and body. Typically, for each command that
        # gets executed by the make_package stage, the head will be the
        # command and the body will be the output of that command.
        # Some log structures might have an empty body, though.
        Schema({
            Required("head"): _nonempty_string,
            Required("kind"): Any("command", "info", "die"),
            Required("time"): (lambda s:
                datetime.strptime(s, "%Y-%m-%dT%H:%M:%S")),
            Required("body"): [
                Schema(_string)
            ]
        })
    ]
})


with open("tuscan/classification_patterns.yaml") as f:
    _patterns = load(f)
_categories = [p["category"] for p in _patterns]


"""Schema for JSON files dumped out of the post-processing stage"""
post_processed_schema = Schema({
    Required("build_name"): _nonempty_string,
    Required("bootstrap"): bool,
    Required("return_code"): All(int, Range(min=0)),
    Required("time"): All(int, Range(min=0)),
    Required("toolchain"): _nonempty_string,
    Required("build_provides"): list,
    Required("build_depends"): list,
    # Which packages is this build blocking? If this package failed to
    # build but all its dependencies built successfully, then this
    # package is said to be a "blocker" and this list will contain all
    # packages that transitively depend on it.
    Required("blocks"): [_nonempty_string],
    # Which builds are blocking this build? If a build of this package
    # was not attempted because some of its dependencies failed to
    # build, then this list will contain those dependencies. Note that
    # if A blocks B from building and C depends on B, then A (but not B)
    # is said to block C. Note that if a package is a blocker, but it
    # has no dependencies, then it's "blocks" list will be empty.
    Required("blocked_by"): [_nonempty_string],
    Required("errors"): list,
    # Status of all configure checks in this build, combined.
    # If a single configure check returned non-zero, then False;
    # If all configure checks returned zero, then True;
    # If we couldn't figure out the return code of any configure check,
    #    then None.
    Required("config_success"): Any(bool, None),
    # This counts how many of each kind of error category were
    # encountered for this build. It is a map error_category =>
    # frequency, where the keys for error_category must be one of the
    # categories in tuscan/classification_patterns.yaml.
    Required("category_counts"): Schema({
        Any(*_categories): int
    }),
    Required("log"): [
        Schema({
            Required("head"): _nonempty_string,
            Required("kind"): Any("command", "info", "die"),
            # If this log is a configure log, then this key reports on
            # whether this invocation of config returned successfully.
            # True if it did, False if it didn't, None if we weren't
            # able to tell. This key does not exist in logs that are not
            # config logs.
            Optional("config_success"): Any(bool, None),
            Required("time"): (lambda s:
                datetime.strptime(s, "%Y-%m-%dT%H:%M:%S")),
            # Post-processing looks through the output of commands, and
            # decorates each line by transforming them from strings into
            # dictionaries.  For each line in the command output, the
            # line goes into the "text" key. The "category" key is used
            # to describe what kind of error that line represents, if
            # any. The valid categories are those defined in
            # classification_patterns.yaml, or None if the line is not
            # an error message.
            Required("body"): [Schema({
                Required("text"): _string,
                Required("id"): int,
                Required("category"): Any(None, *_categories),
                Required("severity"): Any("error", "diagnostic", None),
                Required("semantics"): Schema({
                    _nonempty_string: _nonempty_string
                })
            })]
        })
    ]
})

"""Schema for error classification patterns"""
classification_schema = Schema([Schema({
    # A regex to match a line from the build log against. If the line
    # matches the pattern, it will be classified as 'category'. If the
    # pattern contains one or more _named_ subgroups, then the
    # post-processed log line will contain a hash as the value of the
    # 'semantics' key; each key of the hash will be the name of a
    # subgroup, and the value will be the value of that subgroup.
    #
    # E.g. if we have:
    #     pattern: ": (?P<file>.+?): cannot execute binary file"
    #     category: "exec_error"
    # And a line from the log file:
    #     Horrible error: ./a.out: cannot execute binary file
    # Then post-processing will turn that line into
    #    {"text": "Horrible error: ./a.out: cannot execute binary file",
    #     "category": "exec_error",
    #     "semantics": {"file": "./a.out"}}
    Required("pattern"): _nonempty_string,
    Required("category"): _nonempty_string,
    Required("severity"): Any("error", "diagnostic")
})])
